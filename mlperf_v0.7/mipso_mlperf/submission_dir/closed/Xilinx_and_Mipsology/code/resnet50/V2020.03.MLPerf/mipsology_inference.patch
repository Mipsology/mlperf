diff --git a/vision/classification_and_detection/measurement_server_README.md b/vision/classification_and_detection/measurement_server_README.md
new file mode 100644
index 0000000..6de4f33
--- /dev/null
+++ b/vision/classification_and_detection/measurement_server_README.md
@@ -0,0 +1,62 @@
+# MLPerf Inference using Zebra on Alveo U250
+
+
+## Prepare mlperf environment
+
+   * compile loadgen
+
+   * install imagenet database and set the ```DATA_DIR``` variables
+
+```bash
+export DATA_DIR=path_to_imagenet_directory
+```
+
+   * download resnet50 models:
+
+```bash
+mkdir MODELS
+wget -P MODELS https://zenodo.org/record/2535873/files/resnet50_v1.pb
+export MODEL_DIR=$PWD/MODELS
+```
+
+   * install original tensorflow version 1.14 using pip:
+
+```bash
+python3 -m pip install --user tensorflow==1.14
+```
+
+## Perform Zebra quantization and preparation
+
+```bash
+./mipso_prepare.sh
+```
+
+This execution will perform the quantization of the original neural network
+using the cal_image_list_option_1 sub-dataset.
+
+Then it will prepare the configuration files for the offline scenario and server
+scenario.
+
+
+## Offline execution
+
+```bash
+# run performance tests
+./mipso_offline.sh
+
+# run accuracy tests
+./mipso_offline.sh --accuracy
+```
+
+
+## Server execution
+
+
+```bash
+# run performance tests
+./mipso_server.sh
+
+# run accuracy tests
+./mipso_server.sh --accuracy
+```
+
diff --git a/vision/classification_and_detection/mipso_offline.sh b/vision/classification_and_detection/mipso_offline.sh
new file mode 100755
index 0000000..3c17ff0
--- /dev/null
+++ b/vision/classification_and_detection/mipso_offline.sh
@@ -0,0 +1,10 @@
+#! /bin/bash
+### RUN PARAMETERS
+
+BATCHSIZE=48
+QPS=5050
+
+set -e
+. mipso_options.sh
+
+ ZEBRA_SNAPSHOT_DIRECTORY=${ZEBRA_SNAPSHOT}_${BATCHSIZE} ./run_local.sh tf resnet50 cpu --max-batchsize ${BATCHSIZE} --scenario Offline --threads 1 --qps $QPS "$@"
diff --git a/vision/classification_and_detection/mipso_options.sh b/vision/classification_and_detection/mipso_options.sh
new file mode 100644
index 0000000..6f5e236
--- /dev/null
+++ b/vision/classification_and_detection/mipso_options.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+
+zebraModels=models.zebra
+export ZEBRA_FREQUENCY=680
+export ZEBRA_QUANTIZATION_BATCH_SIZE=500
+export ZEBRA_MODELS=$zebraModels
+export ZEBRA_SNAPSHOT=$zebraModels/snapshot_${HOSTNAME}
diff --git a/vision/classification_and_detection/mipso_prepare.sh b/vision/classification_and_detection/mipso_prepare.sh
new file mode 100755
index 0000000..cd10c71
--- /dev/null
+++ b/vision/classification_and_detection/mipso_prepare.sh
@@ -0,0 +1,18 @@
+#/bin/bash
+
+set -e
+. mipso_options.sh
+
+### ZEBRA OPTIONS ###
+zebra_config --add runOptimization.frequency=$ZEBRA_FREQUENCY
+zebra_config --add runSession.directory=$ZEBRA_MODELS
+baseCommand="./run_local.sh tf resnet50 cpu --scenario Offline --threads 1 --accuracy --mode framework"
+
+
+ZEBRA_QUANTIZATON_FORCE=true ZEBRA_QUANTIZATION_MINIMALBATCHSIZE=${ZEBRA_QUANTIZATION_BATCH_SIZE} ZEBRA_MEMORYTUNING_ALGORITHM=none $baseCommand --max-batchsize ${ZEBRA_QUANTIZATION_BATCH_SIZE}  --count ${ZEBRA_QUANTIZATION_BATCH_SIZE} --dataset-list ../../calibration/ImageNet/cal_image_list_option_1.txt
+
+for batchsize in 36 48 ; do
+    command="$baseCommand --max-batchsize $batchsize  --count $batchsize"
+    ZEBRA_MEMORYTUNING_FORCE=true ZEBRA_SNAPSHOT_DIRECTORY=${ZEBRA_SNAPSHOT}_${batchsize} $command
+    ZEBRA_SNAPSHOT_DIRECTORY=${ZEBRA_SNAPSHOT}_${batchsize} ZEBRA_SNAPSHOT_MODE=txt $command
+done
diff --git a/vision/classification_and_detection/mipso_server.sh b/vision/classification_and_detection/mipso_server.sh
new file mode 100755
index 0000000..6b6c496
--- /dev/null
+++ b/vision/classification_and_detection/mipso_server.sh
@@ -0,0 +1,9 @@
+#! /bin/bash
+### RUN PARAMETERS
+BATCHSIZE=36
+QPS=4100
+
+set -e
+. mipso_options.sh
+
+ ZEBRA_SNAPSHOT_DIRECTORY=${ZEBRA_SNAPSHOT}_${BATCHSIZE} ./run_local.sh tf resnet50 cpu --max-batchsize ${BATCHSIZE} --scenario Server --threads 1 --qps $QPS "$@"
diff --git a/vision/classification_and_detection/offline_README.md b/vision/classification_and_detection/offline_README.md
new file mode 100644
index 0000000..d52d5bf
--- /dev/null
+++ b/vision/classification_and_detection/offline_README.md
@@ -0,0 +1,62 @@
+# MLPerf Inference using Zebra on Alveo U250
+
+
+## Prepare mlperf environment
+
+   * compile loadgen
+
+   * install imagenet database and set the ```DATA_DIR``` variables
+
+``
+export DATA_DIR=path_to_imagenet_directory
+``
+
+   * download resnet50 models:
+
+``
+mkdir MODELS
+wget -P MODELS https://zenodo.org/record/2535873/files/resnet50_v1.pb
+export MODEL_DIR=$PWD/MODELS
+``
+
+   * install original tensorflow version 1.14 using pip:
+
+``
+python3 -m pip install --user tensorflow==1.14
+``
+
+## Perform Zebra quantization and preparation
+
+``
+./mipso_prepare.sh
+``
+
+This execution will perform the quantization of the original neural network
+using the cal_image_list_option_1 sub-dataset.
+
+Then it will prepare the configuration files for the offline scenario and server
+scenario.
+
+
+## Offline execution
+
+``
+# run performance tests
+./mipso_offline.sh
+
+# run accuracy tests
+./mipso_offline.sh --accuracy
+``
+
+
+## Server execution
+
+
+``
+# run performance tests
+./mipso_server.sh
+
+# run accuracy tests
+./mipso_server.sh --accuracy
+``
+
diff --git a/vision/classification_and_detection/python/backend_tf_zebra.py b/vision/classification_and_detection/python/backend_tf_zebra.py
new file mode 100644
index 0000000..9562adc
--- /dev/null
+++ b/vision/classification_and_detection/python/backend_tf_zebra.py
@@ -0,0 +1,40 @@
+# ===========================================================
+# Copyright(C) 2015-2020 Mipsology SAS.  All Rights Reserved.
+# ===========================================================
+
+"""
+zebra tensorflow backend (https://github.com/tensorflow/tensorflow)
+"""
+
+# pylint: disable=unused-argument,missing-docstring,useless-super-delegation
+
+import backend_tf
+
+import numpy as np
+try:
+  import zebra
+except:
+  zebra = None
+
+class BackendTensorflowZebra(backend_tf.BackendTensorflow):
+    def __init__(self):
+        super(BackendTensorflowZebra, self).__init__()
+        self.snapshot_runner = None
+
+    def load_snapshot(self, server = False):
+        if server:
+            self.server = zebra.Server(zebra.SYSTEM)
+        else:
+            self.server = zebra.Server(zebra.NONE)
+
+    def simple_run(self, feed):
+        self.server_upload(feed)
+        return self.server_download()
+
+    def server_upload(self, img):
+        self.server.upload(list(img.values())[0])
+
+    def server_download(self):
+        inf = self.server.download()
+        argmax = np.argmax(inf, 1)
+        return [argmax]
diff --git a/vision/classification_and_detection/python/imagenet.py b/vision/classification_and_detection/python/imagenet.py
index 57865c6..3685870 100755
--- a/vision/classification_and_detection/python/imagenet.py
+++ b/vision/classification_and_detection/python/imagenet.py
@@ -49,7 +49,8 @@ class Imagenet(dataset.Dataset):
         start = time.time()
         with open(image_list, 'r') as f:
             for s in f:
-                image_name, label = re.split(r"\s+", s.strip())
+                # workaround because label is missing in the calibration data set
+                image_name, label, *_  = re.split(r"\s+", s.strip()) + [-1]
                 src = os.path.join(data_path, image_name)
                 if not os.path.exists(src):
                     # if the image does not exists ignore it
diff --git a/vision/classification_and_detection/python/main.py b/vision/classification_and_detection/python/main.py
index cd6825f..875f4cb 100755
--- a/vision/classification_and_detection/python/main.py
+++ b/vision/classification_and_detection/python/main.py
@@ -202,6 +202,11 @@ def get_args():
     parser.add_argument("--count", type=int, help="dataset items to use")
     parser.add_argument("--max-latency", type=float, help="mlperf max latency in pct tile")
     parser.add_argument("--samples-per-query", type=int, help="mlperf multi-stream sample per query")
+
+    # Zebra specific args
+    parser.add_argument("--test-run", action="store_true", help="Zebra test run")
+    parser.add_argument("--mode", default="pipeline", help="Choose: framework simple_run pipeline")
+
     args = parser.parse_args()
 
     # don't use defaults in argparser. Instead we default to a dict, override that with a profile
@@ -227,8 +232,8 @@ def get_args():
 
 def get_backend(backend):
     if backend == "tensorflow":
-        from backend_tf import BackendTensorflow
-        backend = BackendTensorflow()
+        from backend_tf_zebra import BackendTensorflowZebra
+        backend = BackendTensorflowZebra()
     elif backend == "onnxruntime":
         from backend_onnxruntime import BackendOnnxruntime
         backend = BackendOnnxruntime()
@@ -261,7 +266,7 @@ class Item:
 
 
 class RunnerBase:
-    def __init__(self, model, ds, threads, post_proc=None, max_batchsize=128):
+    def __init__(self, model, ds, threads, post_proc=None, max_batchsize=128, mode="pipeline"):
         self.take_accuracy = False
         self.ds = ds
         self.model = model
@@ -400,6 +405,13 @@ def add_results(final_results, name, result_dict, result_list, took, show_accura
         len(result_list), buckets_str))
 
 
+# import here so Item is already defined
+# This is a non classic imports order since the Runner class is a parent of the
+# class defined below
+import queue_runner_zebra_offline
+import queue_runner_zebra_server
+
+
 def main():
     global last_timeing
     args = get_args()
@@ -457,27 +469,21 @@ def main():
     #
     count = ds.get_item_count()
 
-    # warmup
-    ds.load_query_samples([0])
-    for _ in range(5):
-        img, _ = ds.get_samples([0])
-        _ = backend.predict({backend.inputs[0]: img})
-    ds.unload_query_samples(None)
 
     scenario = SCENARIO_MAP[args.scenario]
     runner_map = {
         lg.TestScenario.SingleStream: RunnerBase,
         lg.TestScenario.MultiStream: QueueRunner,
-        lg.TestScenario.Server: QueueRunner,
-        lg.TestScenario.Offline: QueueRunner
+        lg.TestScenario.Server: queue_runner_zebra_server.QueueRunnerZebraServer,
+        lg.TestScenario.Offline: queue_runner_zebra_offline.QueueRunnerZebraOffline
     }
-    runner = runner_map[scenario](model, ds, args.threads, post_proc=post_proc, max_batchsize=args.max_batchsize)
+    runner = runner_map[scenario](model, ds, args.threads, post_proc=post_proc, max_batchsize=args.max_batchsize, mode=args.mode)
 
     def issue_queries(query_samples):
         runner.enqueue(query_samples)
 
     def flush_queries():
-        pass
+        runner.finish_queries()
 
     def process_latencies(latencies_ns):
         # called by loadgen to show us the recorded latencies
@@ -514,6 +520,9 @@ def main():
         settings.server_target_latency_ns = int(args.max_latency * NANO_SEC)
         settings.multi_stream_target_latency_ns = int(args.max_latency * NANO_SEC)
 
+    if args.scenario == 'Server':
+        runner.create_server()
+
     sut = lg.ConstructSUT(issue_queries, flush_queries, process_latencies)
     qsl = lg.ConstructQSL(count, min(count, 500), ds.load_query_samples, ds.unload_query_samples)
 
diff --git a/vision/classification_and_detection/python/queue_runner_zebra_offline.py b/vision/classification_and_detection/python/queue_runner_zebra_offline.py
new file mode 100644
index 0000000..7f7eb18
--- /dev/null
+++ b/vision/classification_and_detection/python/queue_runner_zebra_offline.py
@@ -0,0 +1,219 @@
+# ===========================================================
+# Copyright(C) 2015-2020 Mipsology SAS.  All Rights Reserved.
+# ===========================================================
+
+import array
+import time
+from queue import Queue
+import numpy as np
+import threading
+from statistics import median, mean
+
+import mlperf_loadgen as lg
+from main import Item
+from main import RunnerBase
+
+class QueueRunnerZebraOffline(RunnerBase):
+    def __init__(self, model, ds, threads, post_proc=None, max_batchsize=128, mode="pipeline"):
+        super().__init__(model, ds, threads, post_proc, max_batchsize)
+        self.tasks = Queue(maxsize=threads * 4)
+        self.workers = []
+        self.result_dict = {}
+        self.mode = mode
+        if self.mode != "framework":
+            self.model.load_snapshot(False)
+
+        for _ in range(self.threads):
+            worker = threading.Thread(target=self.handle_tasks, args=(self.tasks,))
+            worker.daemon = True
+            self.workers.append(worker)
+            worker.start()
+
+    def post_process_mipso(self, qitem, results):
+        # run the prediction
+        processed_results = []
+        try:
+            processed_results = self.post_process(results, qitem.content_id, qitem.label, self.result_dict)
+            if self.take_accuracy:
+                self.post_process.add_results(processed_results)
+                self.result_timing.append(time.time() - qitem.start)
+        except Exception as ex:  # pylint: disable=broad-except
+            src = [self.ds.get_item_loc(i) for i in qitem.content_id]
+            log.error("thread: failed on contentid=%s, %s", src, ex)
+            # since post_process will not run, fake empty responses
+            processed_results = [[]] * len(qitem.query_id)
+        finally:
+            response_array_refs = []
+            response = []
+            for idx, query_id in enumerate(qitem.query_id):
+                response_array = array.array("B", np.array(processed_results[idx], np.float32).tobytes())
+                response_array_refs.append(response_array)
+                bi = response_array.buffer_info()
+                response.append(lg.QuerySampleResponse(query_id, bi[0], bi[1]))
+            lg.QuerySamplesComplete(response)
+
+    def getItem(self, tasks_queue, timeout):
+        try:
+            # TODO: we have a timeout because None is sent only once all results are returned
+            return tasks_queue.get(block=True, timeout=timeout)
+        except:
+            return None
+
+    def handle_tasks(self, tasks_queue):
+        if self.mode == "framework":
+            self.zebra(tasks_queue)
+        elif self.mode == "simple_run":
+            self.simple_run(tasks_queue)
+        elif self.mode == "pipeline":
+            self.pipeline(tasks_queue)
+        else:
+             log.error("Unknown mode")
+
+    def server(self, tasks_queue):
+        firstRun = True
+        while True:
+            startTime = time.time()
+            qitem = self.getItem(tasks_queue, None if firstRun else 1)
+            if qitem is None:
+                tasks_queue.task_done()
+                break
+
+            endQueueTime = time.time()
+            queue_time_t = (endQueueTime - startTime)*1000
+            self.model.server_upload({self.model.inputs[0]: qitem.img})
+            uploadTime = time.time()
+            upload_time_t = (uploadTime - endQueueTime)*1000
+            results = self.model.server_download()
+            download_time_t = (time.time() - uploadTime)*1000
+            self.post_process_mipso(qitem, results)
+            tasks_queue.task_done()
+            firstRun = False
+
+            print("total {:.3f}  queue {:.3f}  upload {:.3f}  download {:.3f}".format((time.time() - startTime)*1000, queue_time_t, upload_time_t, download_time_t))
+
+    def zebra(self, tasks_queue):
+        firstRun = True
+        tot = []
+        theEnd = False
+        while True:
+            while True:
+                startTime = time.time()
+                qitem = self.getItem(tasks_queue, None)
+                if qitem is None:
+                    if theEnd:
+                        return
+                    theEnd = True
+                    tasks_queue.task_done()
+                    break
+                else:
+                    theEnd = False
+
+                endQueueTime = time.time()
+                queue_time_t = (endQueueTime - startTime)*1000
+                results = self.model.predict({self.model.inputs[0]: qitem.img})
+                run_t = (time.time() - endQueueTime)*1000
+
+                self.post_process_mipso(qitem, results)
+                tasks_queue.task_done()
+                firstRun = False
+                total_t = (time.time() - startTime)*1000
+                tot += [total_t]
+
+                print("total {:.3f}   run {:.3f}   queue {:.3f}".format(total_t, run_t, queue_time_t))
+            print ("Mean  {:.3f}   Median  {:.3f}".format(mean(tot), median(tot)))
+
+    def simple_run(self, tasks_queue):
+        firstRun = True
+        tot = []
+        theEnd = False
+        while True:
+            while True:
+                startTime = time.time()
+                qitem = self.getItem(tasks_queue, None)
+                if qitem is None:
+                    if theEnd:
+                        return
+                    theEnd = True
+                    tasks_queue.task_done()
+                    break
+                else:
+                    theEnd = False
+
+                endQueueTime = time.time()
+                queue_time_t = (endQueueTime - startTime)*1000
+                results = self.model.simple_run({self.model.inputs[0]: qitem.img})
+                run_t = (time.time() - endQueueTime)*1000
+
+                self.post_process_mipso(qitem, results)
+                tasks_queue.task_done()
+                firstRun = False
+                total_t = (time.time() - startTime)*1000
+                tot += [total_t]
+
+                print("total {:.3f}   run {:.3f}   queue {:.3f}".format(total_t, run_t, queue_time_t))
+            print ("Mean  {:.3f}   Median  {:.3f}".format(mean(tot), median(tot)))
+
+    def pipeline(self, tasks_queue):
+        def increaseIndex(index):
+            if index >= 1:
+                return 0
+            return index + 1
+
+        while True:
+            stopIteration = False
+            downloadIndex = 0
+            uploadIndex = 0
+            items = [None] * 2
+
+            items[uploadIndex] = self.getItem(tasks_queue, timeout=None)
+            if items[uploadIndex] is None:
+                break
+            self.model.server_upload({self.model.inputs[0]: items[uploadIndex].img})
+            uploadIndex = increaseIndex(uploadIndex)
+            tasks_queue.task_done()
+            items[uploadIndex] = self.getItem(tasks_queue, timeout=1)
+            self.model.server_upload({self.model.inputs[0]: items[uploadIndex].img})
+            uploadIndex = increaseIndex(uploadIndex)
+            tasks_queue.task_done()
+            tot = []
+
+            while True:
+                results = self.model.server_download()
+
+                self.post_process_mipso(items[downloadIndex], results)
+                downloadIndex = increaseIndex(downloadIndex)
+
+                items[uploadIndex] = None if stopIteration else self.getItem(tasks_queue, timeout=0.020)
+                if items[uploadIndex] is not None:
+                    self.model.server_upload({self.model.inputs[0]: items[uploadIndex].img})
+                    uploadIndex = increaseIndex(uploadIndex)
+                    tasks_queue.task_done()
+                else:
+                    stopIteration = True
+                if items[downloadIndex] is None:
+                    break
+
+
+    def enqueue(self, query_samples):
+        idx = [q.index for q in query_samples]
+        query_id = [q.id for q in query_samples]
+        if len(query_samples) < self.max_batchsize:
+            data, label = self.ds.get_samples(idx)
+            self.tasks.put(Item(query_id, idx, data, label))
+        else:
+            bs = self.max_batchsize
+            for i in range(0, len(idx), bs):
+                ie = i + bs
+                data, label = self.ds.get_samples(idx[i:ie])
+                self.tasks.put(Item(query_id[i:ie], idx[i:ie], data, label))
+
+    def finish_queries(self):
+        self.tasks.put(None)
+
+
+    def finish(self):
+        # exit all threads
+        for _ in self.workers:
+            self.tasks.put(None)
+        for worker in self.workers:
+            worker.join()
diff --git a/vision/classification_and_detection/python/queue_runner_zebra_server.py b/vision/classification_and_detection/python/queue_runner_zebra_server.py
new file mode 100644
index 0000000..0ec5861
--- /dev/null
+++ b/vision/classification_and_detection/python/queue_runner_zebra_server.py
@@ -0,0 +1,86 @@
+# ===========================================================
+# Copyright(C) 2015-2020 Mipsology SAS.  All Rights Reserved.
+# ===========================================================
+
+import array
+import time
+from queue import Queue
+import numpy as np
+
+import mlperf_loadgen as lg
+from main import Item
+from main import RunnerBase
+
+import zebra
+
+class QueueRunnerZebraServer(RunnerBase):
+    def __init__(self, model, ds, threads, post_proc=None, max_batchsize=128, mode="pipeline"):
+        super().__init__(model, ds, threads, post_proc, max_batchsize)
+        self.tasks = Queue()
+        self.workers = []
+        self.result_dict = {}
+        self.server = None
+
+
+    def post_process_mipso(self, qitem, results):
+        # run the prediction
+        processed_results = []
+        try:
+            processed_results = self.post_process(results, qitem.content_id, qitem.label, self.result_dict)
+            if self.take_accuracy:
+                self.post_process.add_results(processed_results)
+                self.result_timing.append(time.time() - qitem.start)
+        except Exception as ex:  # pylint: disable=broad-except
+            src = [self.ds.get_item_loc(i) for i in qitem.content_id]
+            log.error("thread: failed on contentid=%s, %s", src, ex)
+            # since post_process will not run, fake empty responses
+            processed_results = [[]] * len(qitem.query_id)
+        finally:
+            response_array_refs = []
+            response = []
+            for idx, query_id in enumerate(qitem.query_id):
+                response_array = array.array("B", np.array(processed_results[idx], np.float32).tobytes())
+                response_array_refs.append(response_array)
+                bi = response_array.buffer_info()
+                response.append(lg.QuerySampleResponse(query_id, bi[0], bi[1]))
+            lg.QuerySamplesComplete(response)
+
+
+    def create_server(self):
+        self.server = zebra.Server(zebra.SYSTEM)
+
+    def handle_tasks(self, tasks_queue):
+        """Worker thread."""
+        pass
+
+    def enqueue(self, query_samples):
+        idx = [q.index for q in query_samples]
+        query_id = [q.id for q in query_samples]
+        data, label = self.ds.get_samples(idx)
+        uploaded = False
+        while uploaded is False:
+            if not self.server.isFull():
+                self.server.upload(data)
+                uploaded = True
+                self.tasks.put(Item(query_id, idx, data, label))
+            if self.server.isTerminated():
+                results = np.argmax(self.server.download(), 1)
+                for result in results:
+                    self.post_process_mipso(self.tasks.get(),  [np.array([result])])
+                    self.tasks.task_done()
+
+    def finish_queries(self):
+        if self.tasks.qsize() > 0:
+            while self.tasks.qsize() != 0:
+                if self.server.isTerminated():
+                    results = np.argmax(self.server.download(), 1)
+                    for result in results:
+                        self.post_process_mipso(self.tasks.get(), [np.array([result])])
+                        self.tasks.task_done()
+
+    def finish(self):
+        # exit all threads
+        for _ in self.workers:
+            self.tasks.put(None)
+        for worker in self.workers:
+            worker.join()
diff --git a/vision/classification_and_detection/run_local.sh b/vision/classification_and_detection/run_local.sh
index c014fc1..9832384 100755
--- a/vision/classification_and_detection/run_local.sh
+++ b/vision/classification_and_detection/run_local.sh
@@ -5,6 +5,7 @@ source ./run_common.sh
 common_opt="--mlperf_conf ../../mlperf.conf"
 dataset="--dataset-path $DATA_DIR"
 OUTPUT_DIR=`pwd`/output/$name
+
 if [ ! -d $OUTPUT_DIR ]; then
     mkdir -p $OUTPUT_DIR
 fi
